<!DOCTYPE html>
<html id="J-html" class="">
<head>
    <meta charset="UTF-8" />
    <title>
        
            Spark Api
        
    </title>
    <meta name="generator" content="Jekyll" />
    <meta name="author" content="phy" />
    <meta name="description" content="Spark Api 学习" />
    <meta name="keywords" content="Spark,rdd" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
   <link rel="stylesheet" type="text/css" media="all" href="../../../static/style.css" />
    <link rel="stylesheet" type="text/css" media="all" href="../../../static/pygments.css" />

    <!--[if lt IE 9]>
    <script src="http://pp1230.github.io/static/js/html5.js" type="text/javascript"></script>
    <![endif]-->
    <script src="http://pp1230.github.io/static/js/jquery.js" type="text/javascript"></script>
<script type="text/javascript"
 src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body itemscope itemtype="http://schema.org/WebPage" class="home blog lotus index">
    <nav class="lotus-nav">
        <ul>
            
            
            
            
            
                
            
            <li class="home ">
                <a href="/index.html" rel="bookmark" title="首页">
                    <i class="icon-home"></i>
                </a>
                
            </li>
            
            
            
            
            
            <li class="">
                <a href="/archives.html" rel="bookmark" title="文章归档">
                    <i class="icon-reorder"></i>
                </a>
                
            </li>
            
            
            
            
            
            <li class="">
                <a href="/contact.html" rel="bookmark" title="关于我">
                    <i class="icon-envelope-alt"></i>
                </a>
                
            </li>
            
            
            
            
            
            <li class="">
                <a href="/love/shuwei.html" rel="bookmark" title="love shuwei">
                    <i class="icon-heart"></i>
                </a>
                
            </li>
            
            
            
            
            
            <li class="">
                <a href="/resource.html" rel="bookmark" title="资源">
                    <i class="icon-github"></i>
                </a>
                
            </li>
            
        </ul>
    </nav>

    <p class="lotus-breadcrub">
    <a href="http://pp1230.github.io/index.html" rel="nofollow" rel="nofollow" title="首页">Home</a>
    <span> &gt; </span>
    <a href="http://pp1230.github.io/archives.html" rel="nofollow" >Archives</a>
    <span> &gt; </span>
    Spark Api
</p>
<h1 class="lotus-pagetit">Spark Api</h1>
<p class="lotus-meta">Publish: <time class="date" pubdate="July 25, 2016">July 25, 2016</time></p>
<article  itemscope itemtype="http://schema.org/Article" class="lotus-post">
<h1 id="spark-api">SPARK API</h1>

<blockquote>
  <p>Spark Api Docs : <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.package">http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.package</a></p>
</blockquote>

<h2 id="sparkcontext">SparkContext</h2>

<ul>
  <li>
    <p>def
<strong>parallelize[T] (seq: Seq[T], numSlices: Int = defaultParallelism(分组参数，可以为空))(implicit arg0: ClassTag[T]): RDD[T]</strong></p>

    <p>Distribute a local Scala collection to form an RDD.</p>

    <p><strong>Note</strong>:
avoid using parallelize(Seq()) to create an empty RDD. Consider emptyRDD for an RDD with no partitions, or parallelize(Seq<a href="">T</a>) for an RDD of T with empty partitions.
,
Parallelize acts lazily. If seq is a mutable collection and is altered after the call to parallelize and before the first action on the RDD, the resultant RDD will reflect the modified collection. Pass a copy of the argument to avoid this.</p>
  </li>
  <li>
    <p>def
<strong>textFile(path: String, minPartitions: Int = defaultMinPartitions): RDD[String]</strong>
  Read a text file from HDFS, a local file system (available on all nodes), or any Hadoop-supported file system URI, and return it as an RDD of Strings.</p>
  </li>
</ul>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">//从本地文件初始化RDD
</span><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">rdd2</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">"data.txt"</span><span class="o">)</span>
<span class="n">rdd2</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">txt</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">3</span><span class="o">]</span> <span class="n">at</span> <span class="n">textFile</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">27</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">rdd2</span><span class="o">.</span><span class="n">toArray</span>
<span class="n">res2</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">11</span><span class="o">,</span> <span class="mi">222</span><span class="o">,</span> <span class="mi">3333</span><span class="o">,</span> <span class="mi">44444</span><span class="o">)</span></code></pre></div>

<h2 id="rdd">RDD</h2>

<ul>
  <li>
    <p>def
<strong>++(other: RDD[T]): RDD[T]</strong></p>

    <p>Return the union of this RDD and another one(合并两个RDD). Any identical elements will appear multiple times (use .distinct() to eliminate them).</p>
  </li>
  <li>
    <p>def
<strong>aggregate[U] (zeroValue : U)(seqOp: (U, T) ⇒ U, combOp: (U, U) ⇒ U)(implicit arg0: ClassTag[U]): U</strong></p>

    <p>Aggregate the elements of each partition, and then the results for all the partitions, using given combine functions and a neutral “zero value”. This function can return a different result type, U, than the type of this RDD, T. Thus, we need one operation for merging a T into an U and one operation for merging two U’s, as in scala.TraversableOnce. Both of these functions are allowed to modify and return their first argument instead of creating a new U to avoid memory allocation.</p>

    <p><strong>zeroValue</strong>
the initial value for the accumulated result of each partition for the seqOp operator, and also the initial value for the combine results from different partitions for the combOp operator - this will typically be the neutral element (e.g. Nil for list concatenation or 0 for summation)</p>

    <p><strong>seqOp</strong>（聚合函数）
an operator used to accumulate results within a partition</p>

    <p><strong>combOp</strong>（统计函数）
an associative operator used to combine results from different partitions</p>
  </li>
</ul>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">z</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"a"</span><span class="o">,</span><span class="s">"b"</span><span class="o">),</span><span class="mi">2</span><span class="o">)</span>
<span class="n">z</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">ParallelCollectionRDD</span><span class="o">[</span><span class="err">37</span><span class="o">]</span> <span class="n">at</span> <span class="n">parallelize</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">27</span>

<span class="cm">/*函数执行过程
seq:x+a
com:x+xa
seq:x+b
com:xxa+xb
res69: String = xxaxb
*/</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">z</span><span class="o">.</span><span class="n">aggregate</span><span class="o">(</span><span class="s">"x"</span><span class="o">)(</span><span class="k">_</span> <span class="o">+</span> <span class="k">_</span><span class="o">,</span> <span class="k">_</span><span class="o">+</span><span class="k">_</span><span class="o">)</span>
<span class="n">res69</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="n">xxbxa</span></code></pre></div>

<ul>
  <li>
    <p>def
<strong>cache(): RDD.this.type</strong></p>

    <p>Persist this RDD with the default storage level (MEMORY_ONLY).</p>
  </li>
  <li>
    <p>def
<strong>cartesian[U] (other: RDD[U])(implicit arg0: ClassTag[U]): RDD[(T, U)]</strong>(两个rdd做笛卡尔积)
  Return the Cartesian product of this RDD and another one, that is, the RDD of all pairs of elements (a, b) where a is in this and b is in other.</p>
  </li>
</ul>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">//rdd1=1,2,3;rdd3=a,b
</span><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">rdd4</span> <span class="k">=</span> <span class="n">rdd3</span><span class="o">.</span><span class="n">cartesian</span><span class="o">(</span><span class="n">rdd1</span><span class="o">)</span>
<span class="n">rdd4</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="nc">CartesianRDD</span><span class="o">[</span><span class="err">6</span><span class="o">]</span> <span class="n">at</span> <span class="n">cartesian</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">33</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">rdd4</span><span class="o">.</span><span class="n">collect</span>
<span class="n">res7</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">((</span><span class="n">a</span><span class="o">,</span><span class="mi">1</span><span class="o">),</span> <span class="o">(</span><span class="n">a</span><span class="o">,</span><span class="mi">3</span><span class="o">),</span> <span class="o">(</span><span class="n">a</span><span class="o">,</span><span class="mi">2</span><span class="o">),</span> <span class="o">(</span><span class="n">b</span><span class="o">,</span><span class="mi">1</span><span class="o">),</span> <span class="o">(</span><span class="n">b</span><span class="o">,</span><span class="mi">3</span><span class="o">),</span> <span class="o">(</span><span class="n">b</span><span class="o">,</span><span class="mi">2</span><span class="o">))</span></code></pre></div>

<ul>
  <li>def
<strong>collect[U] (f: PartialFunction<a href="Scala偏函数">T, U</a>)(implicit arg0: ClassTag[U]): RDD[U]</strong>
Return an RDD that contains all matching values by applying f.</li>
</ul>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">//定义偏函数,大于1的元素+1
</span><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">pfunc</span> <span class="k">:</span> <span class="kt">PartialFunction</span><span class="o">[</span><span class="kt">Int</span>,<span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span> <span class="k">case</span> <span class="n">s</span> <span class="k">if</span> <span class="n">s</span><span class="o">&gt;</span><span class="mi">1</span> <span class="k">=&gt;</span> <span class="n">s</span><span class="o">+</span><span class="mi">1</span> <span class="o">}</span>
<span class="n">pfunc</span><span class="k">:</span> <span class="kt">PartialFunction</span><span class="o">[</span><span class="kt">Int</span>,<span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="o">&lt;</span><span class="n">function1</span><span class="o">&gt;</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">rdd1</span><span class="o">.</span><span class="n">collect</span>
<span class="n">res29</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">rdd5</span> <span class="k">=</span> <span class="n">rdd1</span><span class="o">.</span><span class="n">collect</span><span class="o">(</span><span class="n">pfunc</span><span class="o">)</span>
<span class="n">rdd5</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">14</span><span class="o">]</span> <span class="n">at</span> <span class="n">collect</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">33</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">rdd5</span><span class="o">.</span><span class="n">collect</span>
<span class="n">res30</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span></code></pre></div>

<ul>
  <li>
    <p>def
<strong>distinct(): RDD[T]</strong></p>

    <p>Return a new RDD containing the distinct elements in this RDD.（去重函数）</p>
  </li>
  <li>
    <p>def
<strong>distinct(numPartitions: Int)(implicit ord: Ordering[T] = null): RDD[T]</strong></p>

    <p>Return a new RDD containing the distinct elements in this RDD.</p>
  </li>
  <li>
    <p>def
<strong>count(): Long</strong></p>

    <p>Return the number of elements in the RDD.(计数函数)</p>
  </li>
  <li>
    <p>def
<strong>countApprox(timeout: Long, confidence: Double = 0.95): PartialResult[BoundedDouble]</strong></p>

    <p>Approximate version of count() that returns a potentially incomplete result within a timeout, even if not all tasks have finished.（计算时间和计算可信度）</p>
  </li>
  <li>
    <p>def
<strong>countApproxDistinct(relativeSD: Double = 0.05): Long</strong></p>

    <p>Return approximate number of distinct elements in the RDD.（统计不同的元素）</p>

    <p>The algorithm used is based on streamlib’s implementation of “HyperLogLog in Practice: Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm”, available here.
relativeSD
Relative accuracy. Smaller values create counters that require more space. It must be greater than 0.000017.</p>
  </li>
</ul>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">3</span><span class="o">,</span><span class="mi">21</span><span class="o">)</span>
<span class="n">data</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">21</span><span class="o">)</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">distrdd</span><span class="o">.</span><span class="n">count</span>
<span class="n">res1</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">5</span>                                                                  
                      <span class="o">^</span>
<span class="c1">//100毫秒计算时间
</span><span class="n">scala</span><span class="o">&gt;</span> <span class="n">distrdd</span><span class="o">.</span><span class="n">countApprox</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
<span class="n">res3</span><span class="k">:</span> <span class="kt">org.apache.spark.partial.PartialResult</span><span class="o">[</span><span class="kt">org.apache.spark.partial.BoundedDouble</span><span class="o">]</span> <span class="k">=</span> <span class="o">(</span><span class="k">final:</span> <span class="err">[5</span><span class="kt">.</span><span class="err">000</span><span class="o">,</span> <span class="mf">5.000</span><span class="err">]</span><span class="o">)</span>

<span class="c1">//不同元素有四个
</span><span class="n">scala</span><span class="o">&gt;</span> <span class="n">distrdd</span><span class="o">.</span><span class="n">countApproxDistinct</span><span class="o">(</span><span class="mf">0.05</span><span class="o">)</span>
<span class="n">res4</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">4</span></code></pre></div>

<ul>
  <li>
    <p>def
<strong>filter(f: (T) ⇒ Boolean): RDD[T]</strong></p>

    <p>Return a new RDD containing only the elements that satisfy a predicate.(筛选函数)</p>
  </li>
</ul>

<div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">distrdd2</span> <span class="k">=</span> <span class="n">distrdd</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="n">s</span><span class="o">/</span><span class="mi">2</span><span class="o">==</span><span class="mi">0</span><span class="o">)</span>
<span class="n">distrdd2</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">5</span><span class="o">]</span> <span class="n">at</span> <span class="n">filter</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">31</span></code></pre></div>


</article>
<p class="lotus-anno">声明: 本文采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/" rel="nofollow" target="_blank" title="自由转载-非商用-非衍生-保持署名">BY-NC-SA</a> 授权。转载请注明转自: <a href="" title="" rel="nofollow">phy</a></p>
<section class="lotus-nextpage fn-clear">
    
    <div class="lotus-nextpage-left"><a class="prev" href="/2016/07/19/clusteredindex.html" rel="prev">&laquo;&nbsp;聚簇索引和非聚簇索引</a></div>
    
    
    <div class="lotus-nextpage-right"><a class="next" href="/2016/07/26/javalambda.html" rel="next">Java Lambda&nbsp;&raquo;</a></div>
    
</section>

<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="/2016/07/25/sparkapi" data-title="Spark Api" data-url="/2016/07/25/sparkapi.html"></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"pp1230"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- 多说公共JS代码 end -->




<footer class="lotus-footer">
	<p>Copyright © 2010–2015 PHY的博客 All rights reserved. Design by <a href="https://github.com/qq472220372" target="_blank">phy</a>.</p>
</footer>
<script src="http://pp1230.github.io/static/js/jquery.scrollTo.js" type="text/javascript"></script>
<script src="http://pp1230.github.io/static/js/iLotus.js" type="text/javascript"></script>
</body>
</html>
